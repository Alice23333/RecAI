# Environment Variables for plugin.py
# Copy this file to plugin.env and fill in your actual values

# Model Configuration
MODEL_PATH=meta-llama/Meta-Llama-3-8B-Instruct

# Embedding API Service (BGE-M3 or similar)
EMBEDDING_API_URL=http://localhost:8010/v1
EMBEDDING_API_KEY=not-needed

# vLLM Endpoints for LLM Inference
# For multiple endpoints, separate with commas
VLLM_ENDPOINTS=http://localhost:8020/v1,http://localhost:8021/v1,http://localhost:8022/v1

# Or configure per data source:
VLLM_ENDPOINTS_STEAM=http://localhost:8020/v1
VLLM_ENDPOINTS_MOVIES=http://localhost:8020/v1
VLLM_ENDPOINTS_TOYS=http://localhost:8020/v1

# Embedding Service for User/Item Similarity Search
EMBEDDING_SERVICE_BASE_URL=http://localhost:5000
EMBEDDING_PORT_STEAM=5003
EMBEDDING_PORT_MOVIES=5004
EMBEDDING_PORT_TOYS=5005

# Data Directory for Embedding Files
EMBEDDING_DATA_DIR=./data/embeddings

# Performance Settings
MAX_WORKERS=8
